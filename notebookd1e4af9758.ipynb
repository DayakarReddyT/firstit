{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport math\nimport pandas as pd\nfrom IPython.display import display","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-26T06:28:04.045520Z","iopub.execute_input":"2022-06-26T06:28:04.046184Z","iopub.status.idle":"2022-06-26T06:28:04.052415Z","shell.execute_reply.started":"2022-06-26T06:28:04.046139Z","shell.execute_reply":"2022-06-26T06:28:04.051187Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\nion = pd.read_csv('../input/dlassign/data1_0.5.csv',header=None)\nion.columns = [\"V1\", \"V2\", \"Class\"]\ndisplay(ion.head())\n\ndf = ion.copy()\n\n\ndf_train = df.sample(frac=0.7, random_state=0)\ndf_valid = df.drop(df_train.index)\n\nmax_ = df_train.max(axis=0)\nmin_ = df_train.min(axis=0)\n\ndf_train = (df_train - min_) / (max_ - min_)\ndf_valid = (df_valid - min_) / (max_ - min_)\ndf_train.dropna(axis=1, inplace=True) \ndf_valid.dropna(axis=1, inplace=True)\n\nX_train = df_train.drop('Class', axis=1)\nX_valid = df_valid.drop('Class', axis=1)\ny_train = df_train['Class']\ny_valid = df_valid['Class']","metadata":{"execution":{"iopub.status.busy":"2022-06-26T06:28:47.525492Z","iopub.execute_input":"2022-06-26T06:28:47.525893Z","iopub.status.idle":"2022-06-26T06:28:47.587288Z","shell.execute_reply.started":"2022-06-26T06:28:47.525858Z","shell.execute_reply":"2022-06-26T06:28:47.586370Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"         V1        V2  Class\n0  0.046000 -0.181767      0\n1  0.102303  0.116327      0\n2 -0.131546 -0.038680      0\n3  0.007224 -0.067146      0\n4  0.112290  0.040584      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.046000</td>\n      <td>-0.181767</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.102303</td>\n      <td>0.116327</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.131546</td>\n      <td>-0.038680</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.007224</td>\n      <td>-0.067146</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.112290</td>\n      <td>0.040584</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\nactivationList = [\"relu\",\"sigmoid\",'softmax']\n\nfor name in activationList:    \n    print('Activation :: ',name)\n    \n    lossList = [\"binary_crossentropy\",\"hinge\",'squared_hinge']\n    \n    for lossName in lossList:\n        model = keras.Sequential([\n        layers.Dense(16, activation=name),\n        layers.Dense(4, activation=name),    \n        layers.Dense(1, activation='sigmoid'),\n        ])  \n        print('')\n        print('Loss Function Used :: ', lossName)\n            \n        model.compile(            \n            optimizer=tf.keras.optimizers.Adam(),\n            loss=\"binary_crossentropy\",\n            metrics=['binary_accuracy'],\n                )\n        early_stopping = keras.callbacks.EarlyStopping(\n        patience=10,\n        min_delta=0.001,\n        restore_best_weights=True,\n            )\n\n        history = model.fit(\n            X_train, y_train,\n            validation_data=(X_valid, y_valid),\n            batch_size=512,\n            epochs=500,\n            callbacks=[early_stopping],            \n            verbose=0, # hide the output because we have so many epochs\n        )\n        history_df = pd.DataFrame(history.history)\n\n\n        print((\"Best Validation Loss: {:0.4f}\" +\\\n              \"\\nBest Validation Accuracy: {:0.4f}\")\\\n              .format(history_df['val_loss'].min(), \n                      history_df['val_binary_accuracy'].max()))\n        print('')\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T06:31:46.408260Z","iopub.execute_input":"2022-06-26T06:31:46.408627Z","iopub.status.idle":"2022-06-26T06:32:04.232872Z","shell.execute_reply.started":"2022-06-26T06:31:46.408587Z","shell.execute_reply":"2022-06-26T06:32:04.231651Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Activation ::  relu\n\nLoss Function Used ::  binary_crossentropy\nBest Validation Loss: 0.6786\nBest Validation Accuracy: 0.5724\n\n\nLoss Function Used ::  hinge\nBest Validation Loss: 0.6834\nBest Validation Accuracy: 0.6078\n\n\nLoss Function Used ::  squared_hinge\nBest Validation Loss: 0.6759\nBest Validation Accuracy: 0.6219\n\nActivation ::  sigmoid\n\nLoss Function Used ::  binary_crossentropy\nBest Validation Loss: 0.6885\nBest Validation Accuracy: 0.5724\n\n\nLoss Function Used ::  hinge\nBest Validation Loss: 0.6831\nBest Validation Accuracy: 0.5724\n\n\nLoss Function Used ::  squared_hinge\nBest Validation Loss: 0.6855\nBest Validation Accuracy: 0.5724\n\nActivation ::  softmax\n\nLoss Function Used ::  binary_crossentropy\nBest Validation Loss: 0.6829\nBest Validation Accuracy: 0.5724\n\n\nLoss Function Used ::  hinge\nBest Validation Loss: 0.6830\nBest Validation Accuracy: 0.5830\n\n\nLoss Function Used ::  squared_hinge\nBest Validation Loss: 0.6824\nBest Validation Accuracy: 0.5724\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n### Based on the above result we conclude the below points\n\n #### 1) we are considering model with hidden layers having RELU activation and output layer having Sigmoid activation function as it gives maximum validation accuracy and minimum validation loss compared to the other activation functions\n \n #### 2) we are considering \"hinge\" as a loss function as it giving better result compared to other loss function shown in above result\n\n #### 3) For learning rate, according to industry experts fixed learnng rate will take more to train the model and it not advisable for real time project so instead of going for fixed learing rate for all the epochs we are using early stopping method which dynamically change the learning rate based on epoch accuracy and loss \n\n\n\n### Maximum Accuracy Achieved : 0.6219\n### Minimum Loss Achieved : 0.6759","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}